{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec202ada",
   "metadata": {},
   "source": [
    "# Assignment2 - Supervised Learning flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a2810",
   "metadata": {},
   "source": [
    "# Part 1(a) Student details:\n",
    "* Please write the First-Name, First letter of Last-Name and last 4 digits of the i.d. for each student. "
   ]
  },
  {
   "cell_type": "code",
   "id": "ca16486b",
   "metadata": {},
   "source": [
    "# stundent details:\n",
    "# Michael O J 5140\n",
    "# Agam M 6895\n",
    "# Ofek L 8567"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "abb64166-b32e-4b86-a7ee-84106c8b3a92",
   "metadata": {},
   "source": [
    "## Part 1(b) - Chat-GPT/other AI-agent/other assistance used:\n",
    "* If you changed the prompt until you got a satisfying answer, please add all versions\n",
    "* don't delete \"pre\" tags, so new-line is supported\n",
    "* double click the following markdown cell to change\n",
    "* press shift+enter to view\n",
    "* Add information:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea93f0d3-7aa1-4a95-b084-395f5f7c6c0c",
   "metadata": {},
   "source": [
    "    #### Add information in this Markdown cell (double click to change, shift-enter to view)\n",
    "<pre>   \n",
    "AI agent name: Coplilot-{Gpt, Claude, etc...}\n",
    "Goal: Help us write proper code, prevent errors and to understand the pipeline better.\n",
    "Propmpt1:\n",
    "    \"Fix the highlighted code\"\n",
    "Propmpt2:\n",
    "    \"Why do i get this error?\"\n",
    "Propmpt3:\n",
    "    \"Explain hyperparameters and their importance in ML\"\n",
    "\n",
    "\n",
    "AI agent name 2:\n",
    "Goal:\n",
    "Propmpt1:\n",
    "\n",
    "Propmpt2:\n",
    "\n",
    "Propmpt3:\n",
    "\n",
    "\n",
    "Other assistanse:\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4fbaab-e5a5-40ed-be0f-9a2cb7931a4b",
   "metadata": {},
   "source": [
    "    ## Part 1(c) - Learning Problem and dataset explaination.\n",
    "* Please explain in one paragraph\n",
    "* don't delete \"pre\" tags, so new-line is supported\n",
    "* double click the following markdown cell to change\n",
    "* press shift+enter to view\n",
    "* Add explaining text:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8565df-2778-4b89-83bd-6b227063789f",
   "metadata": {},
   "source": [
    "    #### Add information in this Markdown cell (double click to change, shift-enter to view)\n",
    "<pre>\n",
    "The learning problem involves predicting the median house value (`MedHouseVal`) based on various features such as the average number of rooms (`AveRooms`), population size (`Population`), and other housing-related attributes. The dataset used for this task is a housing dataset split into training (`housing_train.csv`) and test (`housing_test.csv`) sets. The training set is used to build and optimize machine learning models, while the test set is used to evaluate the model's performance. The goal is to identify the best combination of feature engineering techniques and algorithms to achieve accurate predictions of house prices.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df67c2ee-87c8-499c-a04f-1853c332f51d",
   "metadata": {},
   "source": [
    "## Part 2 - Initial Preparations \n",
    "You could add as many code cells as needed"
   ]
  },
  {
   "cell_type": "code",
   "id": "b29b3454-b568-4614-8017-f15b3c59fc55",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.pipeline import Pipeline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4b47fe56-d611-4b28-be92-673db4d56400",
   "metadata": {},
   "source": [
    "df_train = pd.read_csv(\"housing_train.csv\")\n",
    "df_test = pd.read_csv(\"housing_test.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "53e27610-b640-4db0-80c9-789b5f5fae58",
   "metadata": {},
   "source": "df_train.head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_test.head()",
   "id": "66b1acdd33498f7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# data cleansing\n",
    "def clean_data(df):\n",
    "    for column in df.columns:\n",
    "        missing_percentage = df[column].isnull().mean()\n",
    "        if missing_percentage < 0.1:\n",
    "            df[column].fillna(df[column].median(), inplace=True)\n",
    "        else:\n",
    "            df.dropna(subset=[column], inplace=True)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df\n",
    "\n",
    "def remove_outliers(df, column, threshold=3):\n",
    "    mean = df[column].mean()\n",
    "    std_dev = df[column].std()\n",
    "    lower_bound = mean - threshold * std_dev\n",
    "    upper_bound = mean + threshold * std_dev\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n"
   ],
   "id": "545bb43227862566"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_train = clean_data(df_train)\n",
    "df_train = remove_outliers(df_train, 'MedHouseVal')\n",
    "df_train = remove_outliers(df_train, 'AveRooms')\n",
    "df_train = remove_outliers(df_train, 'Population')"
   ],
   "id": "83d4c1f64ad8db91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "figure, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "col1, col2, col3 = \"AveRooms\", \"Population\", \"MedHouseVal\"\n",
    "\n",
    "axes[0].scatter(df_train[col1], df_train[col2])\n",
    "axes[0].set_xlabel(col1)\n",
    "axes[0].set_ylabel(col2)\n",
    "axes[0].set_title(f'{col1} vs {col2}')\n",
    "\n",
    "axes[1].scatter(df_train[col1], df_train[col3])\n",
    "axes[1].set_xlabel(col1)\n",
    "axes[1].set_ylabel(col3)\n",
    "axes[1].set_title(f'{col1} vs {col3}')\n",
    "\n",
    "axes[2].scatter(df_train[col2], df_train[col3])\n",
    "axes[2].set_xlabel(col2)\n",
    "axes[2].set_ylabel(col3)\n",
    "axes[2].set_title(f'{col2} vs {col3}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "8ffb8d6e77a9933",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "figure , axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].hist(df_train[col1], bins=20, color='red', alpha=0.7)\n",
    "axes[0].set_title(f'{col1} Histogram')\n",
    "\n",
    "axes[1].hist(df_train[col2], bins=20, color='green', alpha=0.7)\n",
    "axes[1].set_title(f'{col2} Histogram')\n",
    "\n",
    "axes[2].hist(df_train[col3], bins=20, color='blue', alpha=0.7)\n",
    "axes[2].set_title(f'{col3} Histogram')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "1ff1cdb1f5ee8e39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr = df_train.corr(method = 'pearson')\n",
    "corr"
   ],
   "id": "7ab2872f11480471",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The purpose of the visualizations is to explore the relationships and distributions of key features in the dataset. Scatter plots are used to examine potential correlations between variables (such as average rooms, population, and median house value), while histograms provide insights into the distribution of each feature, helping to identify patterns, outliers, or skewness in the data.",
   "id": "dbb5a1e77cf11eba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 3 - Experiments\n",
    "You could add as many code cells as needed"
   ],
   "id": "832ff4e246efb172"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Feature engineering options\n",
    "feature_options = [\n",
    "    [],  # No transformation\n",
    "    ['scale'],  # Standard scaling\n",
    "    ['poly2'],  # Polynomial degree 2\n",
    "    ['selectk'],  # Feature selection\n",
    "    ['scale', 'poly2'],  # Scaling + Polynomial\n",
    "    ['scale', 'selectk'],  # Scaling + Feature selection\n",
    "    ['poly2', 'selectk'],  # Polynomial + Feature selection\n",
    "    ['scale', 'poly2', 'selectk']  # All transformations\n",
    "]\n",
    "\n",
    "# Models and their hyperparameters\n",
    "models = {\n",
    "    'LinearRegression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestRegressor(random_state=42),\n",
    "        'params': {'model__n_estimators': [50, 100], 'model__max_depth': [3, 5, None]}\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'model': Ridge(),\n",
    "        'params': {'model__alpha': [0.1, 1, 10]}\n",
    "    },\n",
    "    'NeuralNetwork': {\n",
    "        'model': MLPRegressor(random_state=42, max_iter=500),\n",
    "        'params': {'model__hidden_layer_sizes': [(50,), (100,)], 'model__activation': ['relu', 'tanh']}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor(tree_method='hist', device='cuda', random_state=42),\n",
    "        'params': {'model__n_estimators': [50, 100], 'model__max_depth': [3, 5, None]}\n",
    "    }\n",
    "}\n",
    "results = []\n",
    "\n",
    "X = df_train.drop('MedHouseVal', axis=1)\n",
    "y = df_train['MedHouseVal']"
   ],
   "id": "fb3e6ea8698ff028",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for feats in feature_options:\n",
    "    start_time = time.time()\n",
    "    steps = []\n",
    "    feats_name = []\n",
    "    if 'scale' in feats:\n",
    "        steps.append(('scaler', StandardScaler()))\n",
    "        feats_name.append('scale')\n",
    "    if 'poly2' in feats:\n",
    "        steps.append(('poly', PolynomialFeatures(degree=2, include_bias=False)))\n",
    "        feats_name.append('poly2')\n",
    "    if 'selectk' in feats:\n",
    "        steps.append(('selectk', SelectKBest(score_func=f_regression, k=2)))\n",
    "        feats_name.append('selectk')\n",
    "    for model_name, model_dict in models.items():\n",
    "        print(f\"Running model: {model_name} with features: {feats_name}\")\n",
    "\n",
    "        pipe_steps = steps + [('model', model_dict['model'])]\n",
    "        pipe = Pipeline(pipe_steps)\n",
    "        param_grid = model_dict['params']\n",
    "\n",
    "        grid = GridSearchCV(pipe, param_grid, cv=5, scoring=make_scorer(mean_squared_error, greater_is_better=False), n_jobs=-1)\n",
    "        grid.fit(X, y)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        results.append({\n",
    "            'Feature Engineering': '+'.join(feats_name) if feats_name else 'none',\n",
    "            'Model': model_name,\n",
    "            'Best Params': grid.best_params_,\n",
    "            'CV Mean MSE': -grid.best_score_,\n",
    "            'R² Score':  grid.best_estimator_.score(X, y),\n",
    "            'Elapsed Time (s)': elapsed_time\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('R² Score', ascending=False)\n",
    "display(results_df)"
   ],
   "id": "9ff89902e83f1614",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 4 - Training \n",
    "Use the best combination of feature engineering, model (algorithm and hyperparameters) from the experiment part (part 3)"
   ],
   "id": "8c45f578b62bf1c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_result = results_df.iloc[0]\n",
    "best_features = best_result['Feature Engineering'].split('+') if best_result['Feature Engineering'] != 'none' else []\n",
    "best_model_name = best_result['Model']\n",
    "best_params = {k: v for k, v in best_result['Best Params'].items() if k != 'model__model'}\n",
    "\n",
    "steps = []\n",
    "if 'scale' in best_features:\n",
    "    steps.append(('scaler', StandardScaler()))\n",
    "if 'poly2' in best_features:\n",
    "    steps.append(('poly', PolynomialFeatures(degree=2, include_bias=False)))\n",
    "if 'selectk' in best_features:\n",
    "    steps.append(('selectk', SelectKBest(score_func=f_regression, k=2)))\n",
    "\n",
    "best_model = models[best_model_name]['model']\n",
    "steps.append(('model', best_model))\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.set_params(**best_params)\n",
    "\n",
    "pipeline.fit(X, y)"
   ],
   "id": "f90d70dcb416332d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 5 - Apply on test and show model performance estimation",
   "id": "4e5f796403eda30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_test = df_test.drop('MedHouseVal', axis=1)\n",
    "y_test = df_test['MedHouseVal']\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(pipeline, X_test, y_test, cv=5, scoring=make_scorer(mean_squared_error, greater_is_better=False))\n",
    "mean_cv_mse = -cv_scores.mean()\n",
    "score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"Cross-Validation Mean MSE on Test Set: {mean_cv_mse}\")\n",
    "print(f\"R² Score on Test Set: {score}\")\n",
    "print(f\"Model Accuracy: {score*100:.2f}%\")\n",
    "\n",
    "pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}).head()"
   ],
   "id": "d43183857b054346",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = best_model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    print(\"Feature Importance:\")\n",
    "    display(importance_df)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, residuals, alpha=0.7, color='purple')\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Analysis')\n",
    "plt.show()"
   ],
   "id": "a793ff2aa51876c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
